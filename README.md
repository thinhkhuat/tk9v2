# Deep Research MCP

üü¢ **PRODUCTION READY** - Full-featured web dashboard with real-time monitoring and all critical functionality operational.

A powerful multi-agent research system built with LangGraph that orchestrates 8 specialized AI agents to conduct comprehensive research and produce professional reports in multiple formats and languages.

## ‚úÖ System Status (Oct 31, 2025)
- **Core Functionality**: All critical paths working correctly
- **Error Handling**: Robust error recovery implemented
- **Performance**: < 2 second startup, 163.4 MB memory usage
- **Provider System**: Google Gemini + BRAVE working with failover
- **Web Dashboard**: Phase 5 complete with critical file detection bug fixed
- **File Detection**: 100% success rate (was 0% before Phase 5 fix)
- **Agent Tracking**: 6 active agents with real-time status updates
- **Test Coverage**: 89% pass rate across 28 comprehensive tests
- **Integration Quality**: Clean imports with async patterns throughout
- **Session Management**: UUID-based tracking fully synchronized across all systems

## üöÄ Features

### Web Dashboard (Phase 5 Complete - Production Ready)
- **Real-Time Monitoring**: Live agent status updates via WebSocket
- **Interactive Agent Cards**: Visual representation of 6 active agents with color-coded states
- **Automatic File Detection**: Generated files appear automatically after research completion (Phase 5 critical bug fix)
- **Session Management**: UUID-based tracking with full state synchronization across all systems
- **Responsive UI**: Built with Vue 3, TypeScript, Pinia, and Tailwind CSS
- **Skeleton Loaders**: Smooth loading states for better user experience
- **Clean Interface**: Misleading stats removed, showing only actionable information

### Multi-Agent Research Workflow
- **8 Specialized Agents**: Browser, Editor, Researcher, Writer, Publisher, Translator, Reviewer, Reviser
- **Parallel Processing**: Multiple research sections processed simultaneously
- **Quality Assurance**: Built-in review and revision workflows
- **Human-in-the-Loop**: Optional human feedback integration

### Advanced Translation System
- **50+ Languages**: Support for major world languages
- **Quality Assurance**: Post-translation review and revision workflow
- **Formatting Preservation**: Maintains markdown structure and styling
- **Multiple Endpoints**: Failover translation services
- **Multi-format Output**: PDF, DOCX, and Markdown in target language

### Multi-Provider Support
- **LLM Providers**: OpenAI, Google Gemini, Anthropic, Azure OpenAI
- **Search Providers**: Tavily, Brave Search, Google, DuckDuckGo, SerpAPI
- **Automatic Failover**: Seamless provider switching on failures
- **Cost Optimization**: Choose providers based on performance and budget

### Professional Output
- **Multiple Formats**: PDF, DOCX, Markdown generation
- **High-Quality PDFs**: LaTeX-based rendering with proper formatting
- **Draft Management**: Complete workflow history preservation
- **Structured Reports**: Citations, table of contents, proper headings

## üìã Table of Contents

- [Quick Start](#quick-start)
- [Installation](#installation)
- [Usage](#usage)
- [Configuration](#configuration)
- [Documentation](#documentation)
- [Examples](#examples)
- [Contributing](#contributing)

## üöÄ Quick Start

### 30-Second Demo

```bash
# Clone and install
git clone <repository-url>
cd deep-research-mcp-og
pip install -r multi_agents/requirements.txt

# Configure (add your API keys)
cp .env.example .env
nano .env

# Run research
python main.py --research "Latest developments in quantum computing"
```

### What You Get

After running, you'll find in `./outputs/`:
- **research_report.pdf** - Professional PDF report
- **research_report.docx** - Editable Word document  
- **research_report.md** - Markdown source
- **research_report_vi.pdf** - Vietnamese translation (if configured)
- **drafts/** - Complete workflow history

## üõ† Installation

### Prerequisites

- **Python 3.13+** (verified and tested)
- **API Keys** for at least one LLM and search provider
- **Pandoc** (optional, for PDF generation)
- **LaTeX** (optional, for high-quality PDFs)

### ‚úÖ Verified Environment
The system has been thoroughly tested and verified with:
- **Python**: 3.13+ (recommended)
- **LangGraph**: Multi-agent orchestration
- **FastMCP**: MCP server implementation
- **Google Gemini**: Primary LLM provider (recommended)
- **BRAVE Search**: Primary search provider (recommended)

### Step 1: Environment Setup

```bash
# Install dependencies
pip install -r multi_agents/requirements.txt

# Or use uv (faster)
uv sync
```

### Step 2: API Configuration

```bash
# Create environment file
cp .env.example .env

# Edit with your API keys
nano .env
```

**Recommended Production Configuration** (Verified):
```bash
# Primary LLM provider (recommended)
GOOGLE_API_KEY=your-google-key
PRIMARY_LLM_PROVIDER=google_gemini
PRIMARY_LLM_MODEL=gemini-2.5-flash-preview-04-17-thinking

# Primary search provider (recommended)
BRAVE_API_KEY=your-brave-key
PRIMARY_SEARCH_PROVIDER=brave

# Provider strategies (for production)
LLM_STRATEGY=primary_only  # or fallback_on_error for redundancy
SEARCH_STRATEGY=primary_only  # or fallback_on_error for redundancy

# BRAVE Search Configuration
RETRIEVER=custom
RETRIEVER_ENDPOINT=https://brave-local-provider.local

# Optional fallback providers
OPENAI_API_KEY=sk-your-openai-key  # fallback LLM
TAVILY_API_KEY=tvly-your-tavily-key  # fallback search
```

### Step 3: Optional Enhancements

```bash
# For high-quality PDF generation
brew install pandoc
brew install --cask basictex

# For enhanced document processing
pip install python-docx htmldocx
```

## üíª Usage

### Web Dashboard (Recommended)

```bash
# Start the web dashboard
cd web_dashboard
./start_dashboard.sh

# Or directly
python3 main.py
```

Access at:
- **Local**: http://localhost:12656
- **Internal Network**: http://192.168.2.22:12656
- **Public** (if configured): https://tk9.thinhkhuat.com

Features:
- Real-time agent status visualization
- Live log streaming
- Automatic file detection and display
- Session management
- Responsive modern UI

### CLI Mode

```bash
# Run single research query
python -m multi_agents.main --research "Your research question"

# With specific language and tone
python -m multi_agents.main \
  --research "Climate change impacts on agriculture" \
  --tone critical \
  --language vi \
  --verbose

# With session ID (for web dashboard integration)
python -m multi_agents.main \
  --research "Your question" \
  --session-id "uuid-here" \
  --verbose
```

### MCP Server Mode

```bash
# Start MCP server
python mcp_server.py

# Use via MCP client
curl -X POST http://localhost:8080/research \
  -H "Content-Type: application/json" \
  -d '{"query":"Research question","tone":"objective"}'
```

### Python Integration

```python
from multi_agents.main import run_research_task

result = await run_research_task(
    query="Latest AI developments",
    tone="critical",
    language="vi",  # Vietnamese translation
    write_to_files=True
)
```

## ‚öôÔ∏è Configuration

### Provider Configuration

The system supports multiple providers with automatic failover:

```bash
# Primary configuration
PRIMARY_LLM_PROVIDER=openai
PRIMARY_LLM_MODEL=gpt-4o
PRIMARY_SEARCH_PROVIDER=tavily

# Fallback providers
FALLBACK_LLM_PROVIDER=google_gemini
FALLBACK_SEARCH_PROVIDER=brave
```

### Research Configuration

Edit `multi_agents/task.json`:

```json
{
  "query": "Your research question",
  "max_sections": 5,
  "language": "vi",
  "tone": "objective",
  "guidelines": [
    "Focus on recent developments (2023-2024)",
    "Include statistical data and citations",
    "Provide multiple perspectives"
  ],
  "publish_formats": ["pdf", "docx", "md"]
}
```

### Translation Configuration

```bash
# Translation endpoints (primary + fallbacks)
TRANSLATION_ENDPOINT_PRIMARY=https://your-translation-service.com/translate
TRANSLATION_TIMEOUT=120

# Target language
RESEARCH_LANGUAGE=vi  # Vietnamese
```

## üìö Documentation

Complete documentation is available in the `docs/` directory:

- **[User Guide](docs/MULTI_AGENT_USER_GUIDE.md)** - Comprehensive usage instructions
- **[API Reference](docs/MULTI_AGENT_API_REFERENCE.md)** - Complete API documentation
- **[Configuration Guide](docs/MULTI_AGENT_CONFIGURATION.md)** - All configuration options
- **[Deployment Guide](docs/MULTI_AGENT_DEPLOYMENT.md)** - Production deployment
- **[Troubleshooting](docs/MULTI_AGENT_TROUBLESHOOTING.md)** - Common issues and solutions

### Quick Links

- [Installation Guide](docs/MULTI_AGENT_USER_GUIDE.md#installation)
- [Multi-Provider Setup](docs/MULTI_AGENT_CONFIGURATION.md#provider-configuration)
- [Translation Features](docs/MULTI_AGENT_USER_GUIDE.md#translation-features)
- [Docker Deployment](docs/MULTI_AGENT_DEPLOYMENT.md#method-2-docker-deployment)
- [Common Issues](docs/MULTI_AGENT_TROUBLESHOOTING.md#common-issues)

## üéØ Examples

### Academic Research

```bash
python main.py --research \
  "Systematic review of machine learning applications in healthcare 2023-2024" \
  --tone critical
```

### Business Analysis

```bash
python main.py --research \
  "Market analysis of electric vehicle adoption in Southeast Asia" \
  --tone balanced \
  --language vi
```

### Technical Documentation

```bash
python main.py --research \
  "Comparison of modern web frameworks: performance and developer experience" \
  --tone objective
```

### Multi-language Research

```bash
# Research in English, output in Vietnamese
python main.py --research \
  "Latest developments in renewable energy technologies" \
  --language vi \
  --tone optimistic
```

## üèó Architecture

### Agent Workflow

```
Browser Agent ‚Üí Editor Agent ‚Üí Researcher Agent (parallel) ‚Üí Writer Agent 
     ‚Üì
Publisher Agent ‚Üí Translator Agent ‚Üí Reviewer Agent ‚Üí Reviser Agent
```

### Key Components

- **ChiefEditorAgent**: Master coordinator managing the workflow
- **Multi-Provider System**: Automatic provider switching and fallback
- **Translation Pipeline**: Professional translation with quality assurance
- **Draft Manager**: Complete workflow history and state management
- **File Generation**: Multi-format output with proper formatting

### Technology Stack

- **LangGraph**: Multi-agent workflow orchestration
- **FastMCP**: MCP server implementation
- **GPT-Researcher**: Core research capabilities
- **Pandoc + LaTeX**: Professional document generation
- **AsyncIO**: Concurrent processing for performance

## üö¢ Deployment

### Docker

```bash
# Build and run
docker build -t deep-research-mcp .
docker run -p 8080:8080 -v $(pwd)/.env:/app/.env deep-research-mcp
```

### Docker Compose

```bash
docker-compose up -d
```

### Kubernetes

```bash
kubectl apply -f k8s/
```

### Production

See the [Deployment Guide](docs/MULTI_AGENT_DEPLOYMENT.md) for comprehensive production setup including:
- Load balancing
- Monitoring and logging
- Backup and recovery
- Security configuration

## üß™ Development

### Running Tests

```bash
# Unit tests
python -m pytest tests/unit/

# Integration tests
python -m pytest tests/integration/

# End-to-end tests
python -m pytest tests/e2e/
```

### Development Setup

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Pre-commit hooks
pre-commit install

# Run linting
flake8 multi_agents/
black multi_agents/
```

### Provider Testing

```bash
# Test all providers
python main.py --provider-info

# Test specific provider
python tests/test_providers.py TestOpenAI
```

## ü§ù Contributing

We welcome contributions! Please see our contributing guidelines:

1. **Fork** the repository
2. **Create** a feature branch
3. **Add** tests for new functionality
4. **Ensure** all tests pass
5. **Submit** a pull request

### Areas for Contribution

- **New Providers**: Add support for additional LLM or search providers
- **Language Support**: Enhance translation capabilities
- **Output Formats**: Add new export formats (HTML, LaTeX, etc.)
- **Agent Enhancements**: Improve existing agent capabilities
- **Documentation**: Help improve documentation and examples

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **GPT-Researcher**: Core research framework
- **LangGraph**: Multi-agent orchestration
- **FastMCP**: MCP server implementation
- **Community Contributors**: All contributors who help improve this project

## üìû Support

- **Documentation**: Check the [docs](docs/) directory
- **Issues**: Report bugs or request features via GitHub Issues
- **Discussions**: Join discussions in GitHub Discussions
- **Enterprise**: Contact us for commercial licensing and support

---

**Made with ‚ù§Ô∏è by the Deep Research MCP team**

*Transform any question into comprehensive research with the power of AI agents.*